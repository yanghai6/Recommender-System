{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JSC370 Recommender Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GUjvLryBzdsx",
        "dfsQoBqcF6to",
        "drJZiqeFLRDX"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAQpYjPVzdsw"
      },
      "source": [
        "# JSC370 Recommendation Systems Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUjvLryBzdsx"
      },
      "source": [
        "## Questions your report should answer:\n",
        "\n",
        "### What value you could add with this data?\n",
        "  - E.g. improve recommendations, suggest friends based on mutual interests, suggest new content to produce / acquire (e.g. Netflix)\n",
        "\n",
        "### How to measure success?\n",
        "  - E.g. Dollars of revenue, chance of liking a selected movie, increasing star-hours watched.  Must make proposed counterfactuals explicit - e.g. not making recommendation, or recommending worse movies.\n",
        "\n",
        "### Look at the data.\n",
        "  - Try to find outliers / problems in data.\n",
        "  - Give a sense of the range of certainty or amount of data per decision that needs to be made.  What is the distribution of number of ratings?\n",
        "  - Look for signs of saturation / overly-coarse granularity.  What is the distribution of ratings?  Could we expect to do better with finer-grained ratings?\n",
        "  - What things depend on e.g. time?\n",
        "\n",
        "### Brainstorm complementary sources of data.\n",
        "  - E.g. More detailed information about movies, the movies themselves, professional ratings\n",
        "\n",
        "### Brainstorm a comprehensive model.\n",
        "  - What are all the factors that could conceivably influence someone's rating?  E.g. a family member uses their account, they want to seem artsy so rate movies highly that they don't actually want to watch, they misunderstand which movie is being rated, their tastes change over time, the movies available to rate change over time, etc.\n",
        "\n",
        "### Propose a model staircase (series of more sophisticated models)\n",
        "  \n",
        "  - You don't have to implement every model you propose!\n",
        "  - It doesn't have to be a strict staircase (each model doesn't have to incorporate the one before it).\n",
        "  - You can propose models that you don't know how to implement.\n",
        "  - Ideally, differences between results will make it clear which inputs / parts of the model are important.\n",
        "  - You need to implement a different number of refinements depending on your group size.\n",
        "      - 1 person: PMF and one variant.\n",
        "      - 2 people: PMF and two variant.\n",
        "      - 2 people: PMF and three variants.\n",
        "  - Suggested variants:\n",
        "      - Using user or movie side info instead of latents\n",
        "      - Using user or movie side info in addition to latents.\n",
        "      - Allowing user latents to be a linear function of time.\n",
        "      - Making the prediction function non-linear.\n",
        "      - Changing the training loss from squared error to something else (e.g. a Dirichlet distribution).\n",
        "\n",
        "### Fit the models + do sanity checks\n",
        "  - This is the coding part of the assignment.\n",
        "  - Include one or two sanity checks, e.g. that accuracy is lower for users with fewer ratings, or that prize-winning movies that you've heard of have higher-than-average ratings.  \n",
        "\n",
        "### Report evidence it works, expected value added, conditions for accurate use.\n",
        "  - Spell out what question the model is answering.  E.g. \"the person logged into this account, on this day, if they watched this movie...\"\n",
        "  - Spell out what question your train/test splits were answering.  E.g. predicting behavior of a random existing user vs a new user.  At a randomly chosen time, or a time after the training data was gathered?  Should correspond to how to shuffled + split the data when training.\n",
        "  - Make improvement clear in terms of your metrics over some baseline.  E.g. \"our best model has x% lower RMSE than simply guessing the mean\".\n",
        "  - Make a link between your improvement of this metric and some metric that a decision-maker might care about.  E.g. \"Each batch of 10 suggestions is approx, y% more likely to contain a movie that a user will rate 5 stars.E.g. \"If users give up after looking at 50 suggestions on average, using our most accurate system will lead to z% more movies watched and rated 5 stars per user per login\".  It's OK to estimate numbers, just make it clear where you're doing so.\n",
        "  - Make statements about what would increase or decrease the accuracy of the model over time.  E.g. many new users joining would hurt accuracy, long-time users sticking around will increase accuracy over time.\n",
        "\n",
        "Assignments will be graded according to [these rubrics](https://jsc370.github.io/2020/assignment_rubrics.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9dHQTK1zds1"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xncf3xm1zds2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60aa83ea-c1a7-4313-c1f0-6fee1e11534b"
      },
      "source": [
        "# import required libraries\n",
        "!pip install wget\n",
        "import os\n",
        "import os.path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import wget\n",
        "\n",
        "import jax.numpy as jnp\n",
        "import numpy.random as npr\n",
        "from jax.api import jit, grad\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1ill6yOzds5"
      },
      "source": [
        "## Support functions and variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNbQGMevzds8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c151e9e4-3661-4221-8441-2f96005383bf"
      },
      "source": [
        "wget.download(\"https://github.com/MIE451-1513-2019/course-datasets/raw/master/ml-100k.zip\")\n",
        "!unzip ml-100k.zip\n",
        "MOVIELENS_DIR = \"ml-100k\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ml-100k.zip\n",
            "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emOWqsTGzdtB"
      },
      "source": [
        "!ls {MOVIELENS_DIR}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3k0-kPF7zdtE"
      },
      "source": [
        "def getData(folder_path, file_name):\n",
        "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
        "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
        "    return data\n",
        "rating_df = getData(MOVIELENS_DIR, 'u.data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RPCAd--22MQ"
      },
      "source": [
        "rating_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpmN2NrTzdtK"
      },
      "source": [
        "num_users = len(rating_df.userID.unique())\n",
        "num_items = len(rating_df.itemID.unique())\n",
        "print(\"Number of users:\", num_users)\n",
        "print(\"Number of items:\", num_items)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip9r8r03MfRi"
      },
      "source": [
        "def dataFrameToArray(rating_df):\n",
        "    \"\"\"\n",
        "        INPUT: \n",
        "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
        "            num_row: int. number of users\n",
        "            num_col: int. number of items\n",
        "            \n",
        "        OUTPUT:\n",
        "            matrix: 2D numpy array. \n",
        "    \"\"\"\n",
        "    matrix = np.zeros((rating_df.shape[0], 4), dtype=np.int32)\n",
        "    # Populate the matrix based on the dataset\n",
        "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
        "        matrix[index, :] = np.array([userID, itemID, rating, timestamp])\n",
        "    return matrix\n",
        "\n",
        "big_array = dataFrameToArray(rating_df)\n",
        "plt.plot(big_array[:,0])\n",
        "\n",
        "# Make train, validation, and test splits\n",
        "train_mat = big_array[:80000, :]\n",
        "valid_mat = big_array[80000:90000, :]\n",
        "test_mat =  big_array[90000:100000, :]\n",
        "\n",
        "train_inputs, train_targets = train_mat[:, :2], train_mat[:, 2].astype(jnp.float32)\n",
        "test_inputs,  test_targets  = test_mat[:, :2],  test_mat[:, 2].astype(jnp.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWyE38dMIK2C"
      },
      "source": [
        "# Model implementation in JAX (https://github.com/google/jax)\n",
        "\n",
        "# Optimization hyperparameters\n",
        "step_size = 100.0\n",
        "train_iters = 1000\n",
        "\n",
        "# Model hyperparameters\n",
        "num_factors = 3\n",
        "init_scale = 0.1\n",
        "latent_param_regularization = 0.1\n",
        "\n",
        "# Init parameters\n",
        "user_latents  = np.random.randn(num_users, num_factors) * init_scale\n",
        "movie_latents = np.random.randn(num_items, num_factors) * init_scale\n",
        "params = (user_latents, movie_latents)\n",
        "\n",
        "# Actual model\n",
        "mean_rating = jnp.mean(train_targets)\n",
        "def pmf_predict(user_latents, movie_latents, inputs):\n",
        "  (user_index,   movie_index) = (inputs[:, 0], inputs[:, 1])\n",
        "  return jnp.sum(user_latents[user_index] * movie_latents[movie_index], axis=1) + mean_rating\n",
        "\n",
        "def regularization_loss(user_latents, movie_latents):\n",
        "  return latent_param_regularization * (jnp.mean(user_latents**2) + jnp.mean(movie_latents**2))\n",
        "\n",
        "def prediction_mse(params, inputs, targets):\n",
        "  preds = pmf_predict(*params, inputs)\n",
        "  return (preds - targets)**2\n",
        "\n",
        "def training_loss(params, inputs, targets):\n",
        "  return regularization_loss(*params) + jnp.mean(prediction_mse(params, inputs, targets), axis=0)\n",
        "\n",
        "# One training step\n",
        "@jit  # Pre-compiles the function to speed up training.\n",
        "def sgd_update(params, i):  # Stochastic gradient descent\n",
        "  (grads_user, grads_movie) = grad(training_loss)(params, train_inputs, train_targets)\n",
        "  (user_latents, movie_latents) = params\n",
        "  return (user_latents  - step_size * grads_user,  # one step of gradient descent\n",
        "          movie_latents - step_size * grads_movie)\n",
        "\n",
        "# Main training loop\n",
        "for i in range(train_iters):\n",
        "  params = sgd_update(params, i)\n",
        "  if i % 100 == 0:\n",
        "    # Print current progress\n",
        "    train_loss = training_loss(params, train_inputs, train_targets)\n",
        "    train_rmse = jnp.sqrt(prediction_mse(params, train_inputs, train_targets))\n",
        "    test_rmse  = jnp.sqrt(prediction_mse(params, test_inputs, test_targets))\n",
        "    print(i, train_loss, jnp.mean(train_rmse), jnp.mean(test_rmse))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BqcT0_zBCOd"
      },
      "source": [
        "plt.plot(pmf_predict(*params, test_mat[0:1000, :2]), test_mat[0:1000, 2].astype(jnp.float32), '.')\n",
        "\n",
        "# How well does predicting the mean do?\n",
        "print(jnp.sqrt(jnp.mean((test_mat[:, 2] - mean_rating)**2)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfZD6lDxcVur"
      },
      "source": [
        "(user_latents, movie_latents) = params\n",
        "plt.plot(user_latents[:, 0], user_latents[:, 1], '.')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsWwaPjaLr8J"
      },
      "source": [
        "plt.plot(movie_latents[:, 0], movie_latents[:, 1], '.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpYvtV9sSwrI"
      },
      "source": [
        "# Sort movies by latent factors, and report \"meaning\" of the different factors.\n",
        "m_cols = ['movie_id', 'title', 'release_date']\n",
        "movies = pd.read_csv(os.path.join(MOVIELENS_DIR, 'u.item'), sep='|', names=m_cols, usecols=range(3),\n",
        "                     encoding='latin-1')\n",
        "\n",
        "least_ixs  = np.argsort(movie_latents[:, 1])[:10]\n",
        "most_ixs  = np.argsort(movie_latents[:, 1])[-10:]\n",
        "\n",
        "print(movies.title[most_ixs])\n",
        "print(movies.title[least_ixs])\n",
        "\n",
        "# Suggestion: Filter out movies with few ratings, since their estimates will be noisiest.\n",
        "\n",
        "# Suggestion: Try different numbers of latent factors and see how accuracy + meaning of factors changes.\n",
        "\n",
        "# Suggestion: Include user side info as predictors and see how accuracy + meaning of factors changes.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-NxXglkRkK9"
      },
      "source": [
        "The cell below is taken from the MIE1513 version of this course - it's just there to give you ideas for other metrics for evaluating your predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-BnXbsLzdul"
      },
      "source": [
        "class CrossValidation(object):\n",
        "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
        "        \"\"\"\n",
        "            INPUT:\n",
        "                metric: string. from['RMSE','P@K','R@K']\n",
        "        \"\"\"\n",
        "        self.folds = self._getData(MOVIELENS_DIR)\n",
        "        self.metric_name = metric\n",
        "        self.metric = self._getMetric(self.metric_name)\n",
        "        \n",
        "    def _getMetric(self, metric_name):\n",
        "        \"\"\"\n",
        "            Don't change this\n",
        "        \"\"\"\n",
        "        switcher = {\n",
        "            'RMSE': self.rmse,\n",
        "            'P@K': self.patk,\n",
        "            'R@K': self.ratk,\n",
        "            'RPrecision': self.rprecision\n",
        "        }\n",
        "        \n",
        "        return switcher[metric_name]\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
        "    \n",
        "    # Precision at k\n",
        "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items retrived\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "    \n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumPrecisions = 0\n",
        "        countPrecisions = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Calculate precision\n",
        "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumPrecisions += precision\n",
        "            countPrecisions += 1\n",
        "\n",
        "        # Return average P@k\n",
        "        return float(sumPrecisions)/countPrecisions\n",
        "    \n",
        "    # Recall at k\n",
        "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame. \n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRecalls = 0\n",
        "        countRecalls = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID,:]\n",
        "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            # Calculate recall\n",
        "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRecalls += recall\n",
        "            countRecalls += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRecalls)/countRecalls\n",
        "\n",
        "    def rprecision(self, data, k, num_users, num_items, pred, true='rating'):\n",
        "        \"\"\"\n",
        "            data: pandas DataFrame.\n",
        "            k: top-k items relevant\n",
        "            pred: string. Column name that corresponding to the prediction\n",
        "            true: string. Column name that corresponding to the true rating\n",
        "        \"\"\"\n",
        "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
        "        testSet    = self.getMatrix(data, num_users, num_items, true)\n",
        "        # Initialize sum and count vars for average calculation\n",
        "        sumRPs = 0\n",
        "        countRPs = 0\n",
        "\n",
        "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
        "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
        "\n",
        "        for userID in range(num_users):\n",
        "            # Pick top K based on predicted rating\n",
        "            userVector = prediction[userID, :]\n",
        "\n",
        "\n",
        "            # Convert test set ratings to like / don't like\n",
        "            userTestVector = vf(testSet[userID, :]).nonzero()[0]\n",
        "\n",
        "            # Ignore user if has no ratings in the test set\n",
        "            if (len(userTestVector) == 0):\n",
        "                continue\n",
        "\n",
        "            topK = nlargest(len(userTestVector), range(len(userVector)), userVector.take)\n",
        "            # Calculate recall\n",
        "            rp = float(len([item for item in topK if item in userTestVector])) / len(userTestVector)\n",
        "\n",
        "            # Update sum and count\n",
        "            sumRPs += rp\n",
        "            countRPs += 1\n",
        "\n",
        "        # Return average R@k\n",
        "        return float(sumRPs) / countRPs\n",
        "\n",
        "    @staticmethod\n",
        "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
        "        matrix = np.zeros((num_users, num_items))\n",
        "    \n",
        "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
        "            matrix[userID-1, itemID-1] = value\n",
        "            \n",
        "        return matrix\n",
        "    \n",
        "    @staticmethod\n",
        "    def _getData(data_path):\n",
        "        \"\"\"\n",
        "            Don't change this function\n",
        "        \"\"\"\n",
        "        folds = []\n",
        "        data_types = ['u{0}.base','u{0}.test']\n",
        "        for i in range(1,6):\n",
        "            train_set = getData(data_path, data_types[0].format(i))\n",
        "            test_set = getData(data_path, data_types[1].format(i))\n",
        "            folds.append([train_set, test_set])\n",
        "        return folds\n",
        "    \n",
        "    def run(self, algorithms, num_users, num_items, k=1):\n",
        "        \"\"\"\n",
        "            5-fold cross-validation\n",
        "            algorithms: list. a list of algorithms. \n",
        "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
        "        \"\"\"\n",
        "        \n",
        "        scores = {}\n",
        "        for algorithm in algorithms:\n",
        "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
        "            fold_scores = []\n",
        "            for fold in self.folds:\n",
        "                algorithm.reset()\n",
        "                algorithm.predict_all(fold[0], num_users, num_items)\n",
        "                prediction = algorithm.evaluate_test(fold[1])\n",
        "                pred_col = algorithm.getPredColName()\n",
        "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
        "                \n",
        "            mean = np.mean(fold_scores)\n",
        "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
        "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
        "            \n",
        "        results = scores    \n",
        "    \n",
        "        return results\n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}